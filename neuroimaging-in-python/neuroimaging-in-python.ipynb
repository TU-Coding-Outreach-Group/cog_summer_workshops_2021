{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Outreach Group Summer Workshop\n",
    "# Neuroimaging in Python\n",
    "\n",
    "07/01/2021\n",
    "\n",
    "**Content creators:** [Elizabeth (Liz) Beard](https://github.com/elizabethbeard), Haroon Popal\n",
    "\n",
    "**Content reviewers:** John Erardi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up & Prerequisites\n",
    "Attendees of this workshop will get the most out of the materials if they have sufficient experience with python and basic functional neuroimaging analysis concepts. Be sure to check out the README for the workshop to make sure you've completed the following steps:\n",
    "1. Installed nltools, datalad, git-annex via homebrew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This workshop is an extremely condensed version of [Luke Chang's DartBrains Course](https://dartbrains.org/content/intro.html). We walk attendees through traditional fMRI analytic steps using python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "| Topic | Time | Description |\n",
    "| --- | --- | --- |\n",
    "| Intro | Why run neuroimaging analyses in python (pros and cons)? What is nltools? | 5 min |\n",
    "| Tutorial 1 | Single subject analysis | 25 min |\n",
    "| Tutorial 2 | Group level analysis | 25 min |\n",
    "| Examples | Unconventional design matricies and further resources | 5 min "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "#intro video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "### datalad\n",
    "\n",
    "### nilearn\n",
    "\n",
    "\n",
    "### nltools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dowloading the Data\n",
    "For this tutorial, we'll be using a subsample of the publically availabily *Localizer Dataset*. The task from this dataset was designed to assess several different types of cognitive processing (visual perception, finger tapping, language, and math). The trials are randomized across conditions and have been optimized to maximize efficiency for a rapid event related design. There are 100 trials in total over a 5-minute scanning session. For more information about this datset, check out the [original paper](https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-8-91).\n",
    "\n",
    "Well be using DataLad to download a subset of about 5 participants onto our local machine for the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Datalad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have anaconda\n",
    "#!conda install -c conda-forge datalad\n",
    "\n",
    "# If you do not have anaconda, run the line below instead of the one above\n",
    "!pip install datalad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLad currently requires manually installing the git-annex dependency, which is not automatically installed using pip\n",
    "!brew install git-annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "The way DataLad works is that we're only mapping the dataset filepath to our computers for now. Then, we'll download a subset of the subjects that we'd like to work with.\n",
    "- ***note***: Be sure to cd into a directory that actually exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Desktop/datasets/ \n",
    "\n",
    "!datalad install https://gin.g-node.org/ljchang/Localizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;31mERROR  \u001b[0m] cmd:git of version >= 2.19.1 is missing. You have version 2.15.0 [external_versions.py:check:376] (OutdatedExternalDependency) \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!datalad status -d Localizer --annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the data in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nest_asyncio # we'll have to make sure people have this installed as well\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import datalad.api as dl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localizer_path = '/Users/tuk12127/Desktop/datasets/Localizer'\n",
    "\n",
    "dl.clone(source='https://gin.g-node.org/ljchang/Localizer', path=localizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dl.Dataset(localizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ds.status(annex='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.path.join(localizer_path, '*', 'fmriprep', '*', 'func', '*tsv'))\n",
    "file_list.sort()\n",
    "file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ds.get(os.path.join(localizer_path, 'sub-S01'))\n",
    "result = ds.get(glob.glob(os.path.join(localizer_path, '*.json')))\n",
    "result = ds.get(glob.glob(os.path.join(localizer_path, '*.tsv')))\n",
    "result = ds.get(glob.glob(os.path.join(localizer_path, 'phenotype')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 - Single Subject Analyasis\n",
    "## Building Design Matricies\n",
    "First, we'll need to build a model for each subject by building a design matrix for our general linear model. We'll be constructing separate regressors that model different brain processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizbeard/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# libraries\n",
    "from nltools.data import Design_Matrix\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.stats import zscore\n",
    "from bids import BIDSLayout, BIDSValidor\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# directories\n",
    "data_dir = '/Users/tuk12127/Desktop/datasets/Localizer'\n",
    "layout = BIDSLayout(data_dir, derivatives=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in onsets and build our design matrix\n",
    "From DartBrains:\n",
    "> To build the design matrix, we will be using the Design_Matrix class from the nltools toolbox. First, we use pandas to load the text file that contains the onset and duration for each condition of the task. Rows reflect measurements in time sampled at 1/tr cycles per second. Columns reflect distinct conditions. Conditions are either on or off. We then cast this Pandas DataFrame as a Design_Matrix object. Be sure to specify the sampling frequency, which is 1/ð‘¡ð‘Ÿ.\n",
    "\n",
    "This function will load in the bids-formatted events and create a Design_Matrix. For more information on how to use the Design_Matrix tool (for data not in bids format, for example), see [this tutorial](https://nltools.org/auto_examples/01_DataOperations/plot_design_matrix.html#sphx-glr-auto-examples-01-dataoperations-plot-design-matrix-py).\n",
    "\n",
    "We can call `dm.info` to review what parameters are in our design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bids_events(layout, subject):\n",
    "    '''Create a design_matrix instance from BIDS event file'''\n",
    "    \n",
    "    tr = layout.get_tr()\n",
    "    n_tr = nib.load(layout.get(subject=subject, scope='raw', suffix='bold')[0].path).shape[-1]\n",
    "\n",
    "    onsets = pd.read_csv(layout.get(subject=subject, suffix='events')[0].path, sep='\\t')\n",
    "    onsets.columns = ['Onset', 'Duration', 'Stim']\n",
    "    return onsets_to_dm(onsets, sampling_freq=1/tr, run_length=n_tr)\n",
    "\n",
    "dm = load_bids_events(layout, 'S01')\n",
    "dm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call `dm.heatmap()` for a visual representation. This is useful to visually assess your onsent times,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolve with HRF\n",
    "We can now convolve all of the onset regressors with an HRF function using `.convolve()` method. By default it will convolve all regressors with the standard double gamma HRF function, though you can specify custom ones and also specific regressors to convolve.\n",
    "\n",
    "When we look at the new heatmap, we can see that our regressors are now a bit blurrier and reflect the shape of the HRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_conv = dm.convolve()\n",
    "dm_conv.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuisance covariates\n",
    "While there are a number of different nusiance covariates one may want to add to their design matrix, today we'll be focusing on removing variance associated with head motion. Since we're working with fmriprep'd data, we can just pull the six motion confounds from the covariates.tsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = pd.read_csv(layout.get(subject='S01', scope='derivatives', extension='.tsv')[0].path, sep='\\t')\n",
    "\n",
    "mc = covariates[['trans_x','trans_y','trans_z','rot_x', 'rot_y', 'rot_z']]\n",
    "mc.fillna(value=0, inplace=True)\n",
    "\n",
    "cov = Design_Matrix(confounds, sampling_freq=1/layout.get_tr())\n",
    "\n",
    "cov.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join onsets and covariates\n",
    "The last step in creating the design matrix involves combining our onsets with our covariates. Because the Design_Matrix class carries the same features as a pandas DataFrame, we can combine them quite easily.\n",
    "\n",
    "Let's take a look at the final product and save it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_S01 = pd.concat([dm_conv, cov], axis=1)\n",
    "dm_S01.heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the filepath to where you'll save the design matrix\n",
    "dm_S01.to_csv(file='path/to/S01-DesignMatrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's loop through our remaining subjects. As an exercise, try and fill in the necessary info we've left blank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = ['S02', ] # add remaining subjects here\n",
    "\n",
    "for subj in subj_list:\n",
    "    \n",
    "    # load in onsets\n",
    "    dm = load_bids_events(layout, subj)\n",
    "    \n",
    "    # convolve with hrf\n",
    "    dm_conv = # add convolve function here\n",
    "    \n",
    "    # nusiance covariates\n",
    "    covariates = pd.read_csv(layout.get(subject=subj, scope='derivatives', extension='.tsv')[0].path, sep='\\t')\n",
    "\n",
    "    mc = covariates[['trans_x','trans_y','trans_z','rot_x', 'rot_y', 'rot_z']]\n",
    "    mc.fillna(value=0, inplace=True)\n",
    "\n",
    "    cov = Design_Matrix(confounds, sampling_freq=1/layout.get_tr())\n",
    "\n",
    "    # concatenate the two design matricies\n",
    "    dm_concat = # combine the two design matricies here\n",
    "    \n",
    "    # save the design matrix to the same folder you saved our first subject\n",
    "    dm_concat.to_csv(file='path/to/%s-DesignMatrix.csv' % subj, index=False) #fill in file path here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BONUS**: Append runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't append across runs for this localizer task, so maybe add sample code as an example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate GLM for all voxels at the single subject level\n",
    "Now that we have a design matrix for all of our subjects, we can estimate the regression model for all voxels for all subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load brain data\n",
    "First we'll nead to load in our pre-processed fMRI data. We'll load in the data as an nltools `Brain_Data` object. The Brain_Data class represents neuroimaging data as a vector as opposed to a 3-d matrix like other python based neuroimaging tools, which can make it easier to perform data manipulations. For more information about what the Brain_Data class can do, check out the [DartBrains Glossary](https://dartbrains.org/content/Glossary.html#brain-data).\n",
    "- ***note***: The default mask for the Brain_Data object is not the same template that is used in the fmriprep registration, so we'll need to use the subject specific mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localizer_path = layout.get(subject='S01', task='localizer', scope='derivatives', suffix='bold', extension='.nii.gz')[0].path\n",
    "localizer_mask = layout.get(subject='S01', task='localizer', scope='derivatives', suffix='mask', extension='.nii.gz')[0].path\n",
    "\n",
    "data = Brain_Data(localizer_path, mask=localizer_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "To increase the SNR and clean up the data, it's common to apply spatial smoothing. We'll use a traditional 3-d gaussian kernel with a 6mm full width half maximum (FWHM) using the `.smooth()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm = 6\n",
    "smoothed_S01 = data.smooth(fwhm=fwhm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look and compare how this changes the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_S01.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add design matrix\n",
    "Before we can estimate our model, we need to add our design matrix to the Brain_Data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_S01.X = dm_S01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate model for all voxels\n",
    "Now we can use the `.regress()` method to estimate the regression model for all voxels.\n",
    "\n",
    "From DartBrains:\n",
    "> The stats variable is a dictionary with the main results from the regression: a brain image with all of the betas for each voxel, a correspondign image of t-values, p-values, standard error of the estimate, and residuals.The stats variable is a dictionary with the main results from the regression: a brain image with all of the betas for each voxel, a correspondign image of t-values, p-values, standard error of the estimate, and residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_S01 = smoothed.regress()\n",
    "print(stats_S01.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the image to a nifti file. \n",
    "- ***note***: Be sure to update the path you want to save the file to! Try changing the path to your own directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_S01.write(f'S01_betas_denoised_smoothed{fwhm}_preprocessed_fMRI_bold.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's loop through our remaining subjects. As an exercise, try and fill in the necessary info we've left blank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_list = ['S02', ] # add remaining subjects here\n",
    "\n",
    "for subj in subj_list:\n",
    "    \n",
    "    # load in the brain data\n",
    "    localizer_path = layout.get(subject=subj, task='localizer', scope='derivatives', suffix='bold', extension='.nii.gz')[0].path\n",
    "    localizer_mask = layout.get(subject=subj, task='localizer', scope='derivatives', suffix='mask', extension='.nii.gz')[0].path\n",
    "\n",
    "    data = Brain_Data(localizer_path, mask=localizer_mask)\n",
    "    \n",
    "    # smooth\n",
    "    fwhm = 6\n",
    "    smoothed = data.smooth(fwhm=fwhm)\n",
    "    \n",
    "    # add design matrix\n",
    "    smoothed.X = pd.read_csv('path/to/design/matrix/%s-DesignMatrix.csv' % subj) # add in the design matrix path here\n",
    "    \n",
    "    # save out\n",
    "    smoothed.write(f'{subj}_betas_denoised_smoothed{fwhm}_preprocessed_fMRI_bold.nii.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create contrast\n",
    "Now that we have estimated our model, we will likely want to create contrasts to examine brain activation to different conditionsNow that we have estimated our model, we will likely want to create contrasts to examine brain activation to different conditions. Let's take a look at which regions are more involved with visual compared to auditory sensory processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smoothed_S01.X.columns)\n",
    "c1 = np.zeros(len(stats_S01['beta']))\n",
    "c1[[2,3,4,8]] = -1/4 # auditory\n",
    "c1[[0,4,6,9]] = 1/4 # visual\n",
    "\n",
    "vis_aud = stats['beta'] * c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'video_computation_c0', 'horizontal_checkerboard_c0',\n",
    "       'audio_right_hand_c0', 'audio_sentence_c0', 'video_right_hand_c0',\n",
    "       'audio_left_hand_c0', 'video_left_hand_c0', 'vertical_checkerboard_c0',\n",
    "       'audio_computation_c0', 'video_sentence_c0', 'cosine_1', 'cosine_2',\n",
    "       'cosine_3', 'cosine_4', 'poly_0', 'poly_1', 'poly_2', 'poly_3',\n",
    "       'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'trans_x',\n",
    "       'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'trans_x', 'trans_y',\n",
    "       'trans_z', 'rot_x', 'rot_y', 'rot_z', 'trans_x', 'trans_y', 'trans_z',\n",
    "       'rot_x', 'rot_y', 'rot_z', 'diff_spike1', 'diff_spike2', 'diff_spike3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_aud.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Level Analysis - Group Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random-effects GLM\n",
    "For all conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load first-level data for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mean activation in each voxel across participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform one-sample t-test across all voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for odd and even runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test\n",
    "All conditions vs rest (fixation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "#outro video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
